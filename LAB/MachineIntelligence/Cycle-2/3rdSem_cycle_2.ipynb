{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5btlgGd1KhM",
        "outputId": "19ff4222-0b2e-423b-ac77-c54230785605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-06 06:51:14--  https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/SMPTE_Color_Bars.svg/200px-SMPTE_Color_Bars.svg.png\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 198.35.26.112, 2620:0:863:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|198.35.26.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 670 [image/png]\n",
            "Saving to: ‘/content/image.png’\n",
            "\n",
            "\r/content/image.png    0%[                    ]       0  --.-KB/s               \r/content/image.png  100%[===================>]     670  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-06 06:51:14 (354 MB/s) - ‘/content/image.png’ saved [670/670]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/SMPTE_Color_Bars.svg/200px-SMPTE_Color_Bars.svg.png -O /content/image.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3FK4uuvuA0e",
        "outputId": "e93c9a41-e7e6-46a5-9bec-d687259ee4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5272 - accuracy: 0.4404 - val_loss: 1.2925 - val_accuracy: 0.5408\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1397 - accuracy: 0.5981 - val_loss: 1.0983 - val_accuracy: 0.6095\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9999 - accuracy: 0.6477 - val_loss: 1.0278 - val_accuracy: 0.6386\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9039 - accuracy: 0.6851 - val_loss: 0.9161 - val_accuracy: 0.6758\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8325 - accuracy: 0.7074 - val_loss: 0.8961 - val_accuracy: 0.6863\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7774 - accuracy: 0.7270 - val_loss: 0.9036 - val_accuracy: 0.6858\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7296 - accuracy: 0.7434 - val_loss: 0.8608 - val_accuracy: 0.7071\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6859 - accuracy: 0.7582 - val_loss: 0.9759 - val_accuracy: 0.6746\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6469 - accuracy: 0.7734 - val_loss: 0.8623 - val_accuracy: 0.7167\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6086 - accuracy: 0.7871 - val_loss: 0.8962 - val_accuracy: 0.7052\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5729 - accuracy: 0.8006 - val_loss: 0.8575 - val_accuracy: 0.7184\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5431 - accuracy: 0.8078 - val_loss: 0.8703 - val_accuracy: 0.7202\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5094 - accuracy: 0.8212 - val_loss: 0.8885 - val_accuracy: 0.7183\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4811 - accuracy: 0.8281 - val_loss: 0.9442 - val_accuracy: 0.7130\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4569 - accuracy: 0.8376 - val_loss: 0.9639 - val_accuracy: 0.7120\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4311 - accuracy: 0.8468 - val_loss: 1.0091 - val_accuracy: 0.7025\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4103 - accuracy: 0.8547 - val_loss: 0.9857 - val_accuracy: 0.7074\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3869 - accuracy: 0.8618 - val_loss: 1.1117 - val_accuracy: 0.7033\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3648 - accuracy: 0.8696 - val_loss: 1.0822 - val_accuracy: 0.7075\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3453 - accuracy: 0.8781 - val_loss: 1.1627 - val_accuracy: 0.7009\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3245 - accuracy: 0.8831 - val_loss: 1.1640 - val_accuracy: 0.7029\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3095 - accuracy: 0.8887 - val_loss: 1.2420 - val_accuracy: 0.7043\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2892 - accuracy: 0.8967 - val_loss: 1.2539 - val_accuracy: 0.7107\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2745 - accuracy: 0.9007 - val_loss: 1.3352 - val_accuracy: 0.7058\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2600 - accuracy: 0.9071 - val_loss: 1.3653 - val_accuracy: 0.7038\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2425 - accuracy: 0.9124 - val_loss: 1.4371 - val_accuracy: 0.7013\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2363 - accuracy: 0.9150 - val_loss: 1.4754 - val_accuracy: 0.7026\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2226 - accuracy: 0.9202 - val_loss: 1.5612 - val_accuracy: 0.6945\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2142 - accuracy: 0.9226 - val_loss: 1.6258 - val_accuracy: 0.6854\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2061 - accuracy: 0.9261 - val_loss: 1.5930 - val_accuracy: 0.6956\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1967 - accuracy: 0.9297 - val_loss: 1.6776 - val_accuracy: 0.6895\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1949 - accuracy: 0.9287 - val_loss: 1.7082 - val_accuracy: 0.6994\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1777 - accuracy: 0.9351 - val_loss: 1.7830 - val_accuracy: 0.6912\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1775 - accuracy: 0.9364 - val_loss: 1.8193 - val_accuracy: 0.6999\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1722 - accuracy: 0.9391 - val_loss: 1.8778 - val_accuracy: 0.6923\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1636 - accuracy: 0.9412 - val_loss: 1.8658 - val_accuracy: 0.6808\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1601 - accuracy: 0.9423 - val_loss: 2.0996 - val_accuracy: 0.6926\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1623 - accuracy: 0.9436 - val_loss: 1.9526 - val_accuracy: 0.6885\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1564 - accuracy: 0.9450 - val_loss: 2.0817 - val_accuracy: 0.6864\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1460 - accuracy: 0.9487 - val_loss: 2.1339 - val_accuracy: 0.6966\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1419 - accuracy: 0.9493 - val_loss: 2.1486 - val_accuracy: 0.6914\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1423 - accuracy: 0.9497 - val_loss: 2.1353 - val_accuracy: 0.7010\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1441 - accuracy: 0.9498 - val_loss: 2.1756 - val_accuracy: 0.6885\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1362 - accuracy: 0.9515 - val_loss: 2.2856 - val_accuracy: 0.6959\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1262 - accuracy: 0.9553 - val_loss: 2.4059 - val_accuracy: 0.6885\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1321 - accuracy: 0.9537 - val_loss: 2.2824 - val_accuracy: 0.6895\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1259 - accuracy: 0.9564 - val_loss: 2.4338 - val_accuracy: 0.6877\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1338 - accuracy: 0.9522 - val_loss: 2.4310 - val_accuracy: 0.6881\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1216 - accuracy: 0.9573 - val_loss: 2.4614 - val_accuracy: 0.6794\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1241 - accuracy: 0.9562 - val_loss: 2.5814 - val_accuracy: 0.6831\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1270 - accuracy: 0.9555 - val_loss: 2.4565 - val_accuracy: 0.6877\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1227 - accuracy: 0.9569 - val_loss: 2.5607 - val_accuracy: 0.6776\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1163 - accuracy: 0.9588 - val_loss: 2.5171 - val_accuracy: 0.6904\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1212 - accuracy: 0.9591 - val_loss: 2.5605 - val_accuracy: 0.6761\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1121 - accuracy: 0.9616 - val_loss: 2.6354 - val_accuracy: 0.6802\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1130 - accuracy: 0.9596 - val_loss: 2.6752 - val_accuracy: 0.6886\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1150 - accuracy: 0.9609 - val_loss: 2.7091 - val_accuracy: 0.6862\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1069 - accuracy: 0.9631 - val_loss: 2.6651 - val_accuracy: 0.6855\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1137 - accuracy: 0.9617 - val_loss: 2.9218 - val_accuracy: 0.6816\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1139 - accuracy: 0.9613 - val_loss: 2.6723 - val_accuracy: 0.6932\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1104 - accuracy: 0.9639 - val_loss: 2.7959 - val_accuracy: 0.6837\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1062 - accuracy: 0.9643 - val_loss: 2.7850 - val_accuracy: 0.6799\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0995 - accuracy: 0.9658 - val_loss: 2.8382 - val_accuracy: 0.6843\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1114 - accuracy: 0.9626 - val_loss: 2.9293 - val_accuracy: 0.6926\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1035 - accuracy: 0.9653 - val_loss: 2.9253 - val_accuracy: 0.6866\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1059 - accuracy: 0.9645 - val_loss: 2.9703 - val_accuracy: 0.6901\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1010 - accuracy: 0.9654 - val_loss: 2.8386 - val_accuracy: 0.6890\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1017 - accuracy: 0.9651 - val_loss: 2.9855 - val_accuracy: 0.6899\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0920 - accuracy: 0.9690 - val_loss: 2.8831 - val_accuracy: 0.7011\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0969 - accuracy: 0.9663 - val_loss: 2.9171 - val_accuracy: 0.6867\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0980 - accuracy: 0.9670 - val_loss: 2.9867 - val_accuracy: 0.6829\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0912 - accuracy: 0.9691 - val_loss: 2.9572 - val_accuracy: 0.6897\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0978 - accuracy: 0.9676 - val_loss: 3.0598 - val_accuracy: 0.6832\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1032 - accuracy: 0.9664 - val_loss: 3.0550 - val_accuracy: 0.6881\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0913 - accuracy: 0.9696 - val_loss: 3.0238 - val_accuracy: 0.6891\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0973 - accuracy: 0.9665 - val_loss: 3.2155 - val_accuracy: 0.6894\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0908 - accuracy: 0.9699 - val_loss: 3.0991 - val_accuracy: 0.6907\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0941 - accuracy: 0.9695 - val_loss: 3.1387 - val_accuracy: 0.6894\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0934 - accuracy: 0.9693 - val_loss: 3.1226 - val_accuracy: 0.6812\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0908 - accuracy: 0.9702 - val_loss: 3.2471 - val_accuracy: 0.6894\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0955 - accuracy: 0.9684 - val_loss: 3.1720 - val_accuracy: 0.6869\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0863 - accuracy: 0.9713 - val_loss: 3.2093 - val_accuracy: 0.6853\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0905 - accuracy: 0.9705 - val_loss: 3.0852 - val_accuracy: 0.6906\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0881 - accuracy: 0.9706 - val_loss: 3.1973 - val_accuracy: 0.6892\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0896 - accuracy: 0.9703 - val_loss: 3.2742 - val_accuracy: 0.6846\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1004 - accuracy: 0.9689 - val_loss: 3.1859 - val_accuracy: 0.6848\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0890 - accuracy: 0.9712 - val_loss: 3.3943 - val_accuracy: 0.6833\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0821 - accuracy: 0.9735 - val_loss: 3.2578 - val_accuracy: 0.6877\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0910 - accuracy: 0.9707 - val_loss: 3.3184 - val_accuracy: 0.6871\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0829 - accuracy: 0.9728 - val_loss: 3.4624 - val_accuracy: 0.6850\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0847 - accuracy: 0.9720 - val_loss: 3.3895 - val_accuracy: 0.6865\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0881 - accuracy: 0.9717 - val_loss: 3.2855 - val_accuracy: 0.6838\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0777 - accuracy: 0.9746 - val_loss: 3.3780 - val_accuracy: 0.6876\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0908 - accuracy: 0.9723 - val_loss: 3.4808 - val_accuracy: 0.6787\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0738 - accuracy: 0.9758 - val_loss: 3.4788 - val_accuracy: 0.6783\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0924 - accuracy: 0.9711 - val_loss: 3.4588 - val_accuracy: 0.6895\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0823 - accuracy: 0.9748 - val_loss: 3.4540 - val_accuracy: 0.6841\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0838 - accuracy: 0.9728 - val_loss: 3.4497 - val_accuracy: 0.6855\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0859 - accuracy: 0.9729 - val_loss: 3.5427 - val_accuracy: 0.6791\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0850 - accuracy: 0.9725 - val_loss: 3.4644 - val_accuracy: 0.6818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e76474d46d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Build a small Convolutional Neural Network (CNN) model using any of deep\n",
        "# libraries for:\n",
        "# a) Image Recognition/ Classification*\n",
        "# b) Digit Identification\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load a dataset for image recognition, for example, CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56i8Q5_kwroH",
        "outputId": "13916ac6-bf30-493d-8e88-ceb89ef6e9fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 10s 5ms/step - loss: 1.5324 - accuracy: 0.4413 - val_loss: 1.2791 - val_accuracy: 0.5460\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1683 - accuracy: 0.5853 - val_loss: 1.0717 - val_accuracy: 0.6216\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0177 - accuracy: 0.6449 - val_loss: 1.0321 - val_accuracy: 0.6380\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9247 - accuracy: 0.6761 - val_loss: 0.9559 - val_accuracy: 0.6673\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8548 - accuracy: 0.6993 - val_loss: 0.9066 - val_accuracy: 0.6900\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7985 - accuracy: 0.7183 - val_loss: 0.9120 - val_accuracy: 0.6888\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7489 - accuracy: 0.7360 - val_loss: 0.9014 - val_accuracy: 0.6957\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7084 - accuracy: 0.7513 - val_loss: 0.8838 - val_accuracy: 0.6967\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6716 - accuracy: 0.7626 - val_loss: 0.9468 - val_accuracy: 0.6857\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6335 - accuracy: 0.7760 - val_loss: 0.9063 - val_accuracy: 0.7051\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6018 - accuracy: 0.7868 - val_loss: 0.9363 - val_accuracy: 0.7000\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5707 - accuracy: 0.7979 - val_loss: 0.9508 - val_accuracy: 0.6945\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.5373 - accuracy: 0.8089 - val_loss: 0.9221 - val_accuracy: 0.7028\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5082 - accuracy: 0.8192 - val_loss: 0.9287 - val_accuracy: 0.7072\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4774 - accuracy: 0.8303 - val_loss: 0.9676 - val_accuracy: 0.7017\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4576 - accuracy: 0.8368 - val_loss: 0.9919 - val_accuracy: 0.7049\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4338 - accuracy: 0.8464 - val_loss: 1.0744 - val_accuracy: 0.6929\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4078 - accuracy: 0.8543 - val_loss: 1.1110 - val_accuracy: 0.6898\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3855 - accuracy: 0.8633 - val_loss: 1.1172 - val_accuracy: 0.7023\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3724 - accuracy: 0.8650 - val_loss: 1.1518 - val_accuracy: 0.6986\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3514 - accuracy: 0.8747 - val_loss: 1.2450 - val_accuracy: 0.6869\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3321 - accuracy: 0.8812 - val_loss: 1.2013 - val_accuracy: 0.6931\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3193 - accuracy: 0.8853 - val_loss: 1.2831 - val_accuracy: 0.6958\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2990 - accuracy: 0.8945 - val_loss: 1.3149 - val_accuracy: 0.6866\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2842 - accuracy: 0.8970 - val_loss: 1.3919 - val_accuracy: 0.6914\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2796 - accuracy: 0.8991 - val_loss: 1.3898 - val_accuracy: 0.6875\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2602 - accuracy: 0.9051 - val_loss: 1.4483 - val_accuracy: 0.6904\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2516 - accuracy: 0.9088 - val_loss: 1.5353 - val_accuracy: 0.6862\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2456 - accuracy: 0.9124 - val_loss: 1.5653 - val_accuracy: 0.6847\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2341 - accuracy: 0.9163 - val_loss: 1.5969 - val_accuracy: 0.6855\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2206 - accuracy: 0.9209 - val_loss: 1.7478 - val_accuracy: 0.6837\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2174 - accuracy: 0.9221 - val_loss: 1.7005 - val_accuracy: 0.6830\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2072 - accuracy: 0.9252 - val_loss: 1.7041 - val_accuracy: 0.6797\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1993 - accuracy: 0.9288 - val_loss: 1.8205 - val_accuracy: 0.6774\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1966 - accuracy: 0.9303 - val_loss: 1.8728 - val_accuracy: 0.6765\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1873 - accuracy: 0.9326 - val_loss: 1.9689 - val_accuracy: 0.6793\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1844 - accuracy: 0.9342 - val_loss: 1.9322 - val_accuracy: 0.6741\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1752 - accuracy: 0.9370 - val_loss: 2.0477 - val_accuracy: 0.6759\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1720 - accuracy: 0.9386 - val_loss: 2.0693 - val_accuracy: 0.6830\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1736 - accuracy: 0.9372 - val_loss: 2.1265 - val_accuracy: 0.6814\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1706 - accuracy: 0.9392 - val_loss: 2.1513 - val_accuracy: 0.6743\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1569 - accuracy: 0.9446 - val_loss: 2.1270 - val_accuracy: 0.6744\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1654 - accuracy: 0.9417 - val_loss: 2.1666 - val_accuracy: 0.6795\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1587 - accuracy: 0.9439 - val_loss: 2.1967 - val_accuracy: 0.6812\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1463 - accuracy: 0.9485 - val_loss: 2.2799 - val_accuracy: 0.6741\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1481 - accuracy: 0.9473 - val_loss: 2.3823 - val_accuracy: 0.6656\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1413 - accuracy: 0.9497 - val_loss: 2.3911 - val_accuracy: 0.6742\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1412 - accuracy: 0.9507 - val_loss: 2.3481 - val_accuracy: 0.6778\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1371 - accuracy: 0.9518 - val_loss: 2.4679 - val_accuracy: 0.6724\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1393 - accuracy: 0.9512 - val_loss: 2.4348 - val_accuracy: 0.6755\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1280 - accuracy: 0.9562 - val_loss: 2.5813 - val_accuracy: 0.6720\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1414 - accuracy: 0.9506 - val_loss: 2.6212 - val_accuracy: 0.6755\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1374 - accuracy: 0.9524 - val_loss: 2.6286 - val_accuracy: 0.6643\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1200 - accuracy: 0.9569 - val_loss: 2.6375 - val_accuracy: 0.6709\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1234 - accuracy: 0.9573 - val_loss: 2.6716 - val_accuracy: 0.6668\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1271 - accuracy: 0.9556 - val_loss: 2.6463 - val_accuracy: 0.6753\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1163 - accuracy: 0.9603 - val_loss: 2.8400 - val_accuracy: 0.6719\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1282 - accuracy: 0.9557 - val_loss: 2.7449 - val_accuracy: 0.6697\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1192 - accuracy: 0.9592 - val_loss: 2.7256 - val_accuracy: 0.6757\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1227 - accuracy: 0.9579 - val_loss: 2.8667 - val_accuracy: 0.6704\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1152 - accuracy: 0.9601 - val_loss: 2.9148 - val_accuracy: 0.6608\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1190 - accuracy: 0.9606 - val_loss: 2.9303 - val_accuracy: 0.6707\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1121 - accuracy: 0.9622 - val_loss: 2.9145 - val_accuracy: 0.6682\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1123 - accuracy: 0.9621 - val_loss: 2.9086 - val_accuracy: 0.6709\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1131 - accuracy: 0.9612 - val_loss: 3.0557 - val_accuracy: 0.6682\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1118 - accuracy: 0.9619 - val_loss: 3.0137 - val_accuracy: 0.6696\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1121 - accuracy: 0.9624 - val_loss: 2.9733 - val_accuracy: 0.6688\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1061 - accuracy: 0.9636 - val_loss: 3.0433 - val_accuracy: 0.6711\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1053 - accuracy: 0.9647 - val_loss: 3.1159 - val_accuracy: 0.6681\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1133 - accuracy: 0.9622 - val_loss: 3.0098 - val_accuracy: 0.6728\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1014 - accuracy: 0.9648 - val_loss: 3.1621 - val_accuracy: 0.6727\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1057 - accuracy: 0.9651 - val_loss: 3.1789 - val_accuracy: 0.6660\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1032 - accuracy: 0.9653 - val_loss: 3.1026 - val_accuracy: 0.6708\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0990 - accuracy: 0.9663 - val_loss: 3.1469 - val_accuracy: 0.6677\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1034 - accuracy: 0.9659 - val_loss: 3.1633 - val_accuracy: 0.6662\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1058 - accuracy: 0.9650 - val_loss: 3.1618 - val_accuracy: 0.6648\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0939 - accuracy: 0.9683 - val_loss: 3.2163 - val_accuracy: 0.6752\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.1009 - accuracy: 0.9662 - val_loss: 3.1771 - val_accuracy: 0.6661\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0942 - accuracy: 0.9680 - val_loss: 3.1279 - val_accuracy: 0.6694\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0907 - accuracy: 0.9699 - val_loss: 3.2167 - val_accuracy: 0.6727\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0987 - accuracy: 0.9671 - val_loss: 3.2504 - val_accuracy: 0.6715\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1059 - accuracy: 0.9659 - val_loss: 3.2752 - val_accuracy: 0.6660\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0908 - accuracy: 0.9697 - val_loss: 3.5232 - val_accuracy: 0.6660\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1031 - accuracy: 0.9661 - val_loss: 3.3619 - val_accuracy: 0.6705\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0955 - accuracy: 0.9689 - val_loss: 3.2612 - val_accuracy: 0.6719\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0911 - accuracy: 0.9698 - val_loss: 3.4346 - val_accuracy: 0.6730\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0860 - accuracy: 0.9712 - val_loss: 3.4815 - val_accuracy: 0.6671\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0985 - accuracy: 0.9685 - val_loss: 3.5734 - val_accuracy: 0.6588\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0924 - accuracy: 0.9695 - val_loss: 3.7087 - val_accuracy: 0.6555\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 3.6667 - val_accuracy: 0.6595\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0948 - accuracy: 0.9697 - val_loss: 3.5069 - val_accuracy: 0.6685\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0895 - accuracy: 0.9711 - val_loss: 3.7294 - val_accuracy: 0.6562\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0902 - accuracy: 0.9702 - val_loss: 3.7119 - val_accuracy: 0.6646\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0910 - accuracy: 0.9701 - val_loss: 3.5157 - val_accuracy: 0.6713\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0849 - accuracy: 0.9726 - val_loss: 3.7102 - val_accuracy: 0.6681\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0863 - accuracy: 0.9718 - val_loss: 3.6461 - val_accuracy: 0.6733\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0962 - accuracy: 0.9695 - val_loss: 3.6334 - val_accuracy: 0.6627\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0846 - accuracy: 0.9735 - val_loss: 3.7340 - val_accuracy: 0.6612\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0844 - accuracy: 0.9727 - val_loss: 3.6916 - val_accuracy: 0.6672\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0863 - accuracy: 0.9723 - val_loss: 3.8233 - val_accuracy: 0.6638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e7637ea4c40>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Build a small Convolutional Neural Network (CNN) model using any of deep\n",
        "# libraries for:\n",
        "# a) Image Recognition/ Classification\n",
        "# b) Digit Identification*\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load a dataset for image recognition, for example, CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbFwrRPNwvzW",
        "outputId": "20f44273-6baf-48db-b001-2dd03c9cc472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 131ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         ...,\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 4.476949,\n",
              "          0.      ]],\n",
              "\n",
              "        [[0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         ...,\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ]],\n",
              "\n",
              "        [[0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         ...,\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         ...,\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ]],\n",
              "\n",
              "        [[0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         ...,\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ]],\n",
              "\n",
              "        [[0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         ...,\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ],\n",
              "         [0.      , 0.      , 0.      , ..., 0.      , 0.      ,\n",
              "          0.      ]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#  use Pre-trained CNN models for feature extraction. *\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the VGG16 model pre-trained on ImageNet data\n",
        "base_model = VGG16(weights='imagenet')\n",
        "# Remove the last layer (classification layer) to use it for feature extraction\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
        "\n",
        "# Example: Load an image and extract features\n",
        "img_path = '/content/image.png'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "# Get the features from the pre-trained model\n",
        "features = model.predict(img_array)\n",
        "\n",
        "# Now 'features' contains the extracted features for the input image\n",
        "features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO4AfJ1JcxmI",
        "outputId": "b7b4ac0b-7018-41fc-ad9a-0a7bcb3d6508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow==2.16.0rc0\n",
        "# Install required libraries\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxyPOZFCw48a",
        "outputId": "6e66ed5f-8e05-4689-eacc-e535b95d4baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1/10, Train Loss: 1.8314, Train Accuracy: 0.3139\n",
            "Test Accuracy: 0.4344\n",
            "Epoch 2/10, Train Loss: 1.4847, Train Accuracy: 0.4512\n",
            "Test Accuracy: 0.5311\n",
            "Epoch 3/10, Train Loss: 1.2879, Train Accuracy: 0.5371\n"
          ]
        }
      ],
      "source": [
        "# Implementation of Pre-trained CNN models using transfer learning for\n",
        "# classification/object detections.\n",
        "# a) AlexNet *\n",
        "# b) VGG-16\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load the pre-trained AlexNet model\n",
        "alexnet_model = models.alexnet(pretrained=True)\n",
        "\n",
        "# Adjust the last layer for the CIFAR-10 dataset\n",
        "num_classes = 10\n",
        "alexnet_model.classifier[6] = torch.nn.Linear(4096, num_classes)\n",
        "\n",
        "# Display the modified model architecture\n",
        "print(alexnet_model)\n",
        "\n",
        "# Set the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alexnet_model = alexnet_model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(alexnet_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    alexnet_model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alexnet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted_train = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted_train == labels).sum().item()\n",
        "\n",
        "    # Calculate training accuracy and loss for the current epoch\n",
        "    train_accuracy = correct_train / total_train\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "          f\"Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    alexnet_model.eval()  # Set the model to evaluation mode\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = alexnet_model(images)\n",
        "            _, predicted_test = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted_test == labels).sum().item()\n",
        "\n",
        "    # Calculate testing accuracy for the current epoch\n",
        "    test_accuracy = correct_test / total_test\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sEYmo1ySw7wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46807298-2857-4ed5-fdb6-eb96e8aea5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 17s 10ms/step - loss: 1.4846 - accuracy: 0.4777 - val_loss: 1.2705 - val_accuracy: 0.5544\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2920 - accuracy: 0.5490 - val_loss: 1.2138 - val_accuracy: 0.5723\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2443 - accuracy: 0.5639 - val_loss: 1.1876 - val_accuracy: 0.5844\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2076 - accuracy: 0.5775 - val_loss: 1.1599 - val_accuracy: 0.5890\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1817 - accuracy: 0.5822 - val_loss: 1.1662 - val_accuracy: 0.5894\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1630 - accuracy: 0.5945 - val_loss: 1.1437 - val_accuracy: 0.5963\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1468 - accuracy: 0.5974 - val_loss: 1.1357 - val_accuracy: 0.6030\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.1337 - accuracy: 0.6031 - val_loss: 1.1346 - val_accuracy: 0.6004\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1195 - accuracy: 0.6077 - val_loss: 1.1358 - val_accuracy: 0.6017\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1098 - accuracy: 0.6107 - val_loss: 1.1144 - val_accuracy: 0.6069\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0923 - accuracy: 0.6140 - val_loss: 1.1179 - val_accuracy: 0.6089\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0811 - accuracy: 0.6197 - val_loss: 1.1117 - val_accuracy: 0.6138\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0697 - accuracy: 0.6242 - val_loss: 1.1169 - val_accuracy: 0.6121\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0576 - accuracy: 0.6274 - val_loss: 1.1118 - val_accuracy: 0.6153\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0518 - accuracy: 0.6300 - val_loss: 1.1111 - val_accuracy: 0.6106\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.1111 - accuracy: 0.6106\n",
            "Test accuracy: 0.6105999946594238\n"
          ]
        }
      ],
      "source": [
        "# Implementation of Pre-trained CNN models using transfer learning for\n",
        "# classification/object detections.\n",
        "# a) AlexNet\n",
        "# b) VGG-16*\n",
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define VGG-16 model with pre-trained weights on ImageNet\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model on top of the VGG-16 base\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=15, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the model\n",
        "model.save('vgg16_transfer_learning.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iprejrNbw_C4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61daa315-ac5f-4bd5-894d-62bc3e937bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 20s 12ms/step - loss: 1.5229 - accuracy: 0.4465 - val_loss: 1.2375 - val_accuracy: 0.5520\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1523 - accuracy: 0.5900 - val_loss: 1.0713 - val_accuracy: 0.6214\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9979 - accuracy: 0.6460 - val_loss: 1.0305 - val_accuracy: 0.6395\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9035 - accuracy: 0.6821 - val_loss: 0.9774 - val_accuracy: 0.6595\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8250 - accuracy: 0.7095 - val_loss: 0.9058 - val_accuracy: 0.6868\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7705 - accuracy: 0.7284 - val_loss: 0.8818 - val_accuracy: 0.6987\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7139 - accuracy: 0.7486 - val_loss: 0.8853 - val_accuracy: 0.6961\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6750 - accuracy: 0.7609 - val_loss: 0.8516 - val_accuracy: 0.7096\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6340 - accuracy: 0.7758 - val_loss: 0.8648 - val_accuracy: 0.7071\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5955 - accuracy: 0.7883 - val_loss: 0.8858 - val_accuracy: 0.7064\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5632 - accuracy: 0.8011 - val_loss: 0.8839 - val_accuracy: 0.7135\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5236 - accuracy: 0.8145 - val_loss: 0.9314 - val_accuracy: 0.7049\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4948 - accuracy: 0.8236 - val_loss: 0.9574 - val_accuracy: 0.6975\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4669 - accuracy: 0.8355 - val_loss: 0.9343 - val_accuracy: 0.7090\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4410 - accuracy: 0.8436 - val_loss: 1.0120 - val_accuracy: 0.7044\n",
            "Epoch Details:\n",
            "{'loss': [1.522917628288269, 1.152303695678711, 0.9978633522987366, 0.9035373330116272, 0.8249775767326355, 0.7705489993095398, 0.7139171361923218, 0.6749573945999146, 0.6339873671531677, 0.5954617857933044, 0.5631868243217468, 0.5236361026763916, 0.49480023980140686, 0.46686673164367676, 0.4409768879413605], 'accuracy': [0.4464600086212158, 0.5900400280952454, 0.6459599733352661, 0.6821399927139282, 0.7095000147819519, 0.7283999919891357, 0.7485799789428711, 0.7609000205993652, 0.7757800221443176, 0.7882800102233887, 0.8011199831962585, 0.814520001411438, 0.823639988899231, 0.8355200290679932, 0.8435999751091003], 'val_loss': [1.2375328540802002, 1.0712991952896118, 1.0305263996124268, 0.9774064421653748, 0.9057859182357788, 0.8817617297172546, 0.8852803707122803, 0.8516137599945068, 0.864815354347229, 0.8858087062835693, 0.8838697075843811, 0.9314002990722656, 0.9573913812637329, 0.9342682361602783, 1.0119928121566772], 'val_accuracy': [0.5519999861717224, 0.621399998664856, 0.6395000219345093, 0.659500002861023, 0.6868000030517578, 0.6987000107765198, 0.6960999965667725, 0.7095999717712402, 0.707099974155426, 0.7063999772071838, 0.7135000228881836, 0.7049000263214111, 0.6974999904632568, 0.7089999914169312, 0.7044000029563904]}\n",
            "313/313 - 1s - loss: 1.0120 - accuracy: 0.7044 - 659ms/epoch - 2ms/step\n",
            "\n",
            "Test Accuracy: 0.7044000029563904\n"
          ]
        }
      ],
      "source": [
        "# Practicing various strategies of fine tuning*\n",
        "\n",
        "# Install necessary libraries\n",
        "# !pip install tensorflow\n",
        "\n",
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define a simple convolutional neural network (CNN)\n",
        "def create_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10))\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=15, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Print epoch details and accuracy\n",
        "print(\"Epoch Details:\")\n",
        "print(history.history)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"\\nTest Accuracy: {test_acc}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cn4ZFmRSxAnB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfba729d-4b57-411d-876b-572915ab677b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 3s 5ms/step - loss: 0.2137 - val_loss: 0.1340\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1171 - val_loss: 0.1028\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0965 - val_loss: 0.0891\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0860 - val_loss: 0.0815\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0769\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0762 - val_loss: 0.0742\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0738 - val_loss: 0.0723\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0722 - val_loss: 0.0710\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0710 - val_loss: 0.0700\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0701 - val_loss: 0.0694\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0695 - val_loss: 0.0688\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0689 - val_loss: 0.0683\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0685 - val_loss: 0.0679\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0681 - val_loss: 0.0676\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0678 - val_loss: 0.0675\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0676 - val_loss: 0.0672\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0674 - val_loss: 0.0669\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0668\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0670 - val_loss: 0.0666\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0669 - val_loss: 0.0666\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0668 - val_loss: 0.0664\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0666 - val_loss: 0.0664\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0665 - val_loss: 0.0663\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0665 - val_loss: 0.0662\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0664 - val_loss: 0.0661\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0663 - val_loss: 0.0661\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0660\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0659\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0661 - val_loss: 0.0659\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0661 - val_loss: 0.0659\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0658\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0658\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0658\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0659 - val_loss: 0.0658\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0659 - val_loss: 0.0657\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0659 - val_loss: 0.0657\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0659 - val_loss: 0.0657\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0658 - val_loss: 0.0657\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0658 - val_loss: 0.0657\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0658 - val_loss: 0.0656\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0658 - val_loss: 0.0656\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0658 - val_loss: 0.0656\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0656\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0656\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0656\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0655\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0655\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0655\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0656\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0655\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0656 - val_loss: 0.0655\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0656 - val_loss: 0.0655\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0655\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0654\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0655\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0654\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0655\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0655\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0654\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0654\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0654\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0654\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0654\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0654\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0654\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0654\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0654\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0653\n",
            "313/313 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ImplementingGenerative Models:\n",
        "# a) Autoencoder for image reconstruction*\n",
        "# b) Word Prediction using RNN\n",
        "# c) Image Captioning\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "x_train_flat = x_train.reshape((len(x_train), -1))\n",
        "x_test_flat = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "# Define the autoencoder model\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train_flat, x_train_flat, epochs=100, batch_size=256, shuffle=True, validation_data=(x_test_flat, x_test_flat))\n",
        "\n",
        "# Encode and decode some digits\n",
        "decoded_imgs = autoencoder.predict(x_test_flat)\n",
        "\n",
        "# Display the results\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nrNCEM_6xD2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f933d53b-1e3a-4491-bd8e-1e9fb5deb0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 120ms/step - loss: 4.8648 - accuracy: 0.0178\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 4.8433 - accuracy: 0.0888\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 4.8095 - accuracy: 0.0769\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 4.7440 - accuracy: 0.0651\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 94ms/step - loss: 4.5775 - accuracy: 0.0533\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 4.5393 - accuracy: 0.0533\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 91ms/step - loss: 4.4707 - accuracy: 0.0533\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 4.4499 - accuracy: 0.0533\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 4.4207 - accuracy: 0.0533\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 4.3751 - accuracy: 0.0533\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 4.3420 - accuracy: 0.0592\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 4.3081 - accuracy: 0.1124\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 4.2650 - accuracy: 0.1065\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.2138 - accuracy: 0.1065\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 4.1635 - accuracy: 0.0947\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 86ms/step - loss: 4.0823 - accuracy: 0.1183\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.0168 - accuracy: 0.1361\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.9298 - accuracy: 0.1361\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 3.8438 - accuracy: 0.1479\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.7578 - accuracy: 0.1598\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.6804 - accuracy: 0.1420\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.5730 - accuracy: 0.2012\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 97ms/step - loss: 3.4877 - accuracy: 0.1834\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 3.3842 - accuracy: 0.2189\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.2926 - accuracy: 0.2367\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2032 - accuracy: 0.2308\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1242 - accuracy: 0.2781\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 3.0268 - accuracy: 0.2840\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.9430 - accuracy: 0.2959\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 2.8384 - accuracy: 0.3491\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.7649 - accuracy: 0.3491\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 2.6816 - accuracy: 0.4024\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.5955 - accuracy: 0.4379\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.5558 - accuracy: 0.4142\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 2.5015 - accuracy: 0.4615\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.3974 - accuracy: 0.4615\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.3147 - accuracy: 0.4970\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.2393 - accuracy: 0.4911\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 2.1510 - accuracy: 0.5325\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 2.0947 - accuracy: 0.5621\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.0208 - accuracy: 0.5680\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9715 - accuracy: 0.5858\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 1.9159 - accuracy: 0.6095\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8502 - accuracy: 0.6509\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 1.7944 - accuracy: 0.6331\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7331 - accuracy: 0.6509\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6987 - accuracy: 0.6568\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6458 - accuracy: 0.6627\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5933 - accuracy: 0.6864\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5526 - accuracy: 0.6982\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5061 - accuracy: 0.7219\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4613 - accuracy: 0.7041\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4245 - accuracy: 0.7219\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3981 - accuracy: 0.7278\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3669 - accuracy: 0.7396\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3154 - accuracy: 0.7751\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2718 - accuracy: 0.7692\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2471 - accuracy: 0.7988\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2105 - accuracy: 0.7870\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 1.1844 - accuracy: 0.8284\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1563 - accuracy: 0.8343\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1270 - accuracy: 0.8225\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0947 - accuracy: 0.8343\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 1.0615 - accuracy: 0.8343\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0437 - accuracy: 0.8402\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0093 - accuracy: 0.8521\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9782 - accuracy: 0.8639\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9437 - accuracy: 0.8757\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9195 - accuracy: 0.8817\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9063 - accuracy: 0.8757\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.8776 - accuracy: 0.8817\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.8479 - accuracy: 0.8876\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.8276 - accuracy: 0.9053\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.8090 - accuracy: 0.8994\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.7800 - accuracy: 0.8994\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.7650 - accuracy: 0.9112\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.7418 - accuracy: 0.9231\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.7199 - accuracy: 0.9112\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.7028 - accuracy: 0.9231\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.9290\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.9290\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6531 - accuracy: 0.9349\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.9290\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.9349\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6048 - accuracy: 0.9467\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.9349\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.9467\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.9467\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.9645\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.9704\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.9586\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.9704\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.9704\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.9763\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.9763\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.9763\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.9822\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.9882\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.9882\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.9941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bb6089124a0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# ImplementingGenerative Models:\n",
        "# a) Autoencoder for image reconstruction\n",
        "# b) Word Prediction using RNN *\n",
        "# c) Image Captioning\n",
        "\n",
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Extended corpus with more examples\n",
        "corpus = [\n",
        "    'This is a sample sentence.',\n",
        "    'Word prediction using RNN is interesting.',\n",
        "    'You can replace this dataset with your own data.',\n",
        "    'Machine learning is a rapidly evolving field.',\n",
        "    'Natural language processing is used in many applications.',\n",
        "    'Deep learning models can achieve impressive results.',\n",
        "    'Python is a popular programming language for data science.',\n",
        "    'Recurrent Neural Networks are commonly used in sequence modeling.',\n",
        "    'Artificial Intelligence is transforming various industries.',\n",
        "    'Data preprocessing is a crucial step in machine learning.',\n",
        "    'Image classification is a common computer vision task.',\n",
        "    'Neural networks can be used for both regression and classification.',\n",
        "    'Transfer learning allows models to leverage pre-trained knowledge.',\n",
        "    'The importance of feature engineering in machine learning.',\n",
        "    'Ensemble methods combine multiple models for better performance.',\n",
        "    'Generative Adversarial Networks (GANs) generate realistic data.',\n",
        "    'Support Vector Machines are effective in high-dimensional spaces.',\n",
        "    'Clustering algorithms group similar data points together.',\n",
        "    'Unsupervised learning explores patterns in unlabeled data.',\n",
        "    'Ethical considerations in AI and machine learning.',\n",
        "    'Hyperparameter tuning is essential for model optimization.',\n",
        "    'Cross-validation helps assess the generalization of a model.',\n",
        "    'Bias and fairness in machine learning algorithms.',\n",
        "    'The impact of AI on the job market.',\n",
        "    'Understanding the trade-off between bias and variance.',\n",
        "]\n",
        "\n",
        "# Tokenizing and padding the sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_length = max([len(x) for x in input_sequences])\n",
        "padded_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "# Creating input and output\n",
        "X, y = padded_sequences[:, :-1], padded_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Building and training the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(total_words, 100))\n",
        "model.add(tf.keras.layers.LSTM(100))\n",
        "model.add(tf.keras.layers.Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Model summary\n",
        "# model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SE03-ZsmxF_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "5d1f5387-6643-4eb2-b1c7-50273d61d7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: a tv screen with a colorful pattern\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ImplementingGenerative Models:\n",
        "# a) Autoencoder for image reconstruction\n",
        "# b) Word Prediction using RNN\n",
        "# c) Image Captioning *\n",
        "\n",
        "# !pip install torch\n",
        "# !pip install torchvision\n",
        "# !pip install transformers\n",
        "# !pip install nltk\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load and display the image\n",
        "image_path = \"image.png\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the pre-trained image captioning model\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = \"image.png\"\n",
        "image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "input_tensor = preprocess(image).unsqueeze(0)\n",
        "\n",
        "# Generate captions\n",
        "with torch.no_grad():\n",
        "    captions = model.generate(pixel_values=input_tensor)\n",
        "\n",
        "# Decode the generated captions\n",
        "caption_text = processor.decode(captions[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated caption\n",
        "print(\"Generated Caption:\", caption_text)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiGntvpa96Uv"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LxAxPjR_rR2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVfQdZEUBUFl"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}